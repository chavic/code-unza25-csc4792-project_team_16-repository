{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArbjW_PfCpFQ"
      },
      "source": [
        "# Parliament Relevance Classifier\n",
        "## CSC 4792 Group Project - Team 16\n",
        "\n",
        "**Topic 2.1.10**: Classify each MP's response as *relevant* or *not relevant* to the motion\n",
        "\n",
        "**Team Members**:\n",
        "- Francis Kalunga, 2021518884, francis.kalunga@cs.unza.zm\n",
        "- Victor Chabunda, 2021422496, victor.chabunda@cs.unza.zm\n",
        "- Constance Chilamo, 2021517420, chilamo.constance@cs.unza.zm\n",
        "\n",
        "**Date**: 2025\n",
        "\n",
        "---\n",
        "\n",
        "### Problem Statement\n",
        "Given a motion and the debate transcript for a parliamentary sitting, label every MP utterance as **Relevant** or **NotRelevant** to that motion.\n",
        "\n",
        "### Approach\n",
        "This notebook follows the CRISP-DM methodology through all phases:\n",
        "- **[BU]** Business Understanding\n",
        "- **[DU]** Data Understanding  \n",
        "- **[DP]** Data Preparation\n",
        "- **[MO]** Modeling\n",
        "- **[EV]** Evaluation\n",
        "- **[DE]** Deployment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [BU] Business Understanding\n",
        "\n",
        "Phase: [BU] Business Understanding  \n",
        "Date: 2025  \n",
        "Team: Team 16\n",
        "\n",
        "### Team Members\n",
        "- Francis Kalunga, 2021518884, francis.kalunga@cs.unza.zm\n",
        "- Victor Chabunda, 2021422496, victor.chabunda@cs.unza.zm\n",
        "- Constance Chilamo, 2021517420, chilamo.constance@cs.unza.zm\n",
        "\n",
        "### Problem Statement\n",
        "The Zambian National Assembly generates extensive debate transcripts during parliamentary sittings, but currently lacks an automated system to identify which speaker utterances are directly relevant to the motions being discussed. This creates challenges for:\n",
        "- **Parliamentary staff** who need to index and search through Hansard records efficiently\n",
        "- **Researchers and journalists** who want to analyze parliamentary discourse and voting patterns\n",
        "- **Citizens** who seek to understand how their representatives engage with specific policy issues\n",
        "\n",
        "The problem is to **classify each speaker turn in parliamentary debates as either \"Relevant\" or \"NotRelevant\" to the motion under discussion**, where:\n",
        "- **Relevant**: utterances that argue for/against the motion, provide supporting evidence, propose amendments, or discuss implementation\n",
        "- **NotRelevant**: procedural points, greetings, tangential discussions, jokes, or administrative matters\n",
        "\n",
        "### Business Objectives\n",
        "1. **Improve Accessibility of Parliamentary Records**  \n",
        "   Enable parliamentary staff to automatically classify utterances as relevant or not, making it easier to index, search, and retrieve key information.\n",
        "2. **Support Evidence-Based Research and Journalism**  \n",
        "   Provide researchers and journalists with structured data on parliamentary debates, improving analysis of policy discussions and representative accountability.\n",
        "3. **Enhance Transparency and Civic Engagement**  \n",
        "   Allow citizens and civic organizations to more easily understand how their representatives engage with motions, fostering accountability and democratic participation.\n",
        "4. **Increase Operational Efficiency**  \n",
        "   Reduce the time and effort required for manual annotation and indexing of Hansard records by introducing automation.\n",
        "\n",
        "### Intended Users\n",
        "1. **Parliamentary Information Services** - for automated indexing and search\n",
        "2. **Political researchers** - for discourse analysis and policy tracking  \n",
        "3. **Journalists** - for identifying key arguments and positions on specific motions\n",
        "4. **Civic organizations** - for monitoring representative engagement with issues\n",
        "\n",
        "### Key Performance Indicators (KPIs)\n",
        "**Primary Metrics**\n",
        "- **Macro-F1 Score** ≥ 0.75 (balanced performance across both classes)\n",
        "- **Relevant Class Recall** ≥ 0.80 (capture most relevant utterances)\n",
        "- **Area Under Precision-Recall Curve (AUPRC)** ≥ 0.70 (handle class imbalance)\n",
        "\n",
        "**Secondary Metrics**\n",
        "- Balanced Accuracy ≥ 0.75\n",
        "- Per-sitting performance consistency\n",
        "- Per-speaker performance analysis\n",
        "\n",
        "### Scope and Constraints\n",
        "**In Scope**\n",
        "- Parliamentary debates and proceedings from Zambian National Assembly\n",
        "- English language utterances\n",
        "- Motions from Order Papers (substantive motions, not procedural)\n",
        "- Speaker turns with clear attribution and timestamps\n",
        "\n",
        "**Out of Scope**\n",
        "- Committee proceedings (different format and context)\n",
        "- Question Time sessions (different interaction patterns)\n",
        "- Languages other than English\n",
        "- Real-time classification (batch processing acceptable)\n",
        "\n",
        "**Data Coverage**\n",
        "- Target: 6-10 parliamentary sittings from 2023\n",
        "- Minimum: 1,000 manually labeled utterances for training\n",
        "- Time range: Representative sample across different motion types\n",
        "\n",
        "### Risks and Assumptions\n",
        "**Technical Risks**\n",
        "- **Low inter-annotator agreement** - Complex cases may be subjectively labeled\n",
        "- **Class imbalance** - Most utterances may be relevant, creating skewed training data\n",
        "- **Context dependency** - Relevance may require understanding previous utterances\n",
        "- **Motion complexity** - Compound motions may have multiple relevant topics\n",
        "\n",
        "**Business Risks**\n",
        "- **Annotation quality** - Inconsistent labeling could hurt model performance\n",
        "- **Generalizability** - Model may not work well on different parliamentary systems\n",
        "- **Deployment complexity** - Integration with existing parliamentary systems\n",
        "\n",
        "**Key Assumptions**\n",
        "- Parliamentary transcripts are accurately transcribed with speaker attribution\n",
        "- Order Papers correctly identify the motions being debated\n",
        "- Manual annotation can achieve reasonable consistency (κ ≥ 0.75)\n",
        "- TF-IDF and transformer features will capture relevance patterns effectively\n",
        "\n",
        "### Ethical Considerations\n",
        "- **Transparency**: Classification decisions should be explainable to users\n",
        "- **Bias**: Ensure model doesn't discriminate based on speaker identity or political affiliation  \n",
        "- **Privacy**: No personal information beyond public parliamentary records\n",
        "- **Accuracy**: False classifications could misrepresent parliamentary discourse\n",
        "\n",
        "**Extended Ethical Considerations**\n",
        "- **Transparency and Explainability**: Classification decisions should be explainable to users, enabling parliamentary staff and researchers to understand why utterances are classified as relevant or not relevant. The model should provide confidence scores and feature importance to support decision transparency (Westminster Foundation for Democracy, 2025).\n",
        "- **Political Neutrality and Non-Discrimination**: Ensure the model doesn't discriminate based on speaker identity, political affiliation, or political orientation, as algorithmic bias against political viewpoints can arise in AI systems (Leerssen, 2022). The model should perform consistently across all political parties and individual representatives.\n",
        "- **Fairness Across Demographics**: Minimize bias and ensure fairness across different speaker demographics, including gender, age, constituency, and years of service to prevent systematic disadvantaging of any group (Inter-Parliamentary Union, 2025).\n",
        "- **Data Representativeness**: Address potential correlations that may overlap with protected categories or political viewpoints by ensuring training data represents diverse speakers, motion types, and parliamentary contexts to prevent accidental bias (Wikipedia, 2025).\n",
        "- **Contextual Sensitivity**: Respect the cultural and institutional context of Zambian parliamentary discourse, ensuring the model doesn't impose external definitions of relevance that may not align with local parliamentary traditions and practices.\n",
        "- **Privacy and Consent**: Maintain appropriate handling of public parliamentary records while respecting speaker attribution and ensuring no personal information beyond publicly available Hansard records is used in the classification system.\n",
        "- **Accountability and Human Oversight**: Promote human autonomy and decision-making by designing the system as a decision-support tool rather than a replacement for human judgment, with clear protocols for human review of classifications (Westminster Foundation for Democracy, 2025).\n",
        "- **Impact Assessment**: Monitor for unintended consequences such as potential chilling effects on parliamentary speech or systematic misrepresentation of certain speakers' contributions to debates.\n",
        "\n",
        "**References:**\n",
        "- Inter-Parliamentary Union. (2025). Ethical principles: Fairness and non-discrimination. AI Guidelines for Parliaments.\n",
        "- Leerssen, P. (2022). Algorithmic Political Bias in Artificial Intelligence Systems. Philosophy & Technology, 35(2).\n",
        "- Westminster Foundation for Democracy. (2025). AI guidelines for parliaments.\n",
        "- Wikipedia. (2025). Algorithmic bias.\n",
        "\n",
        "### Success Criteria\n",
        "The project will be considered successful if:\n",
        "1. Achieves target KPI thresholds on held-out test data\n",
        "2. Demonstrates consistent performance across different sittings and speakers\n",
        "3. Provides interpretable predictions with confidence scores\n",
        "4. Delivers a working CLI tool for batch classification\n",
        "5. Completes all CRISP-DM phases with proper documentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [DU] Data Understanding\n",
        "\n",
        "Goal: build a reliable picture of what data exists, what we need to extract, and how it links together so we can prepare high-quality inputs for modeling.\n",
        "\n",
        "### 1) Data landscape (what exists)\n",
        "- Debates & Proceedings (index), plus an alternate debates index with separate pagination. ([1], [10])\n",
        "- Order Papers (index) listing the Order of the Day with the motion text. ([2])\n",
        "- Votes & Proceedings (index) summarizing timing/outcomes for validation. ([3])\n",
        "- Debate pages are Drupal node pages; treat node pages as canonical targets. The site includes PDFs (e.g., abstracts) alongside HTML. ([7], [9])\n",
        "\n",
        "### 2) What we will collect per sitting (artifacts)\n",
        "- Motion (from Order Paper): `motion_text` and relevant metadata. ([2])\n",
        "- Debate content (from Debates): segmented utterances `(speaker, timestamp?, utterance_text, stage_marker?)`. ([7])\n",
        "- Optional validation (from Votes & Proceedings): date/session alignment or outcomes. ([3])\n",
        "\n",
        "### 3) How we will join (keys and gaps)\n",
        "- Primary join key: date; use session header when available for disambiguation.\n",
        "- Expect gaps: some dates appear in one debates index but not the other, or have an Order Paper without a visible debate entry. Crawl both indices; prefer node pages when present. ([1], [10])\n",
        "\n",
        "### 4) Collection strategy (practical crawling)\n",
        "- Pagination: crawl until no more pages (do not hard‑code page counts). OP paginates deeper than Debates. ([2])\n",
        "- Attachments: download linked PDFs under `/sites/default/files/...` and text‑extract alongside HTML.\n",
        "- Polite crawling: throttle requests, set a descriptive user‑agent, use content‑hashing to skip duplicates.\n",
        "- Storage layout: `data/raw/` (HTML/PDF snapshots), `data/interim/` (parsed text, JSONL).\n",
        "\n",
        "### 5) Parsing & intermediate schema\n",
        "- Segment debate pages into utterances using heading patterns and stage markers.\n",
        "- Output: `data/interim/utterances.jsonl` with fields:\n",
        "  - `sitting_id` (e.g., `YYYY-MM-DD`), `assembly_session?`, `speaker`, `timestamp?`, `utterance_text`, `stage_marker?`\n",
        "- Save `motion_text` to `data/interim/<date>_motion.txt` for conditioning.\n",
        "\n",
        "### 6) Quick EDA (sanity checks)\n",
        "- Length distribution of utterances; per‑speaker turn counts; frequency of stage markers.\n",
        "- Lexical‑overlap heuristic vs motion to estimate a rough prior of Relevant/NotRelevant for inspection.\n",
        "- Spot‑check one older sitting to verify parser robustness across templates.\n",
        "\n",
        "### 7) Risks and mitigations\n",
        "- Template drift (old vs new): maintain versioned parsers per template. ([4])\n",
        "- HTML/PDF variance: add a PDF extraction path; keep raw snapshots. ([9])\n",
        "- Ambiguous “relevance” edges: create an annotation guide; double‑label a subset for κ. ([5])\n",
        "- Session/date mismatches: join on date; validate with Votes & Proceedings. ([3])\n",
        "- Dual debates indices: crawl both indices; de‑duplicate node links. ([1], [10])\n",
        "- Attachment links: fetch and extract PDFs to avoid missing content.\n",
        "\n",
        "### 8) Ready‑to‑run checklist\n",
        "- [ ] Crawl 3–5 sittings from both debates indices; store raw HTML/PDF with hashes. ([1], [10])\n",
        "- [ ] Fetch matching Order Papers; save raw and `<date>_motion.txt`. ([2])\n",
        "- [ ] Implement `parse_segment.py` → `data/interim/utterances.jsonl`.\n",
        "- [ ] EDA: length histograms, turns per speaker, marker frequencies; add screenshots of index pages.\n",
        "- [ ] Draft data card with provenance and verbatim references. ([5])\n",
        "\n",
        "[1]: https://www.parliament.gov.zm/publications/debates-list \"Debates and Proceedings | National Assembly of Zambia\"\n",
        "[2]: https://www.parliament.gov.zm/publications/order-paper-list \"Order Paper | National Assembly of Zambia\"\n",
        "[3]: https://www.parliament.gov.zm/publications/votes-proceedings \"Votes and Proceedings | National Assembly of Zambia\"\n",
        "[4]: https://www.parliament.gov.zm/ \"National Assembly of Zambia\"\n",
        "[5]: https://www.parliament.gov.zm/node/173 \"Publications | National Assembly of Zambia\"\n",
        "[7]: https://www.parliament.gov.zm/node/1401 \"Debates- Thursday, 4th November, 2010\"\n",
        "[9]: https://www.parliament.gov.zm/sites/default/files/images/publication_docs/Abstract%202%20Debate%20In%20Parliament.pdf \"Abstract 2 Debate In Parliament.pdf\"\n",
        "[10]: https://www.parliament.gov.zm/publications/debates-proceedings \"Debates & Proceedings (alternate) | National Assembly of Zambia\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [DP] Data Preparation\n",
        "\n",
        "Goal: clean, transform, and prepare structured inputs for modeling.  \n",
        "This section builds on the raw crawled artifacts (`/data/raw/`) and outputs\n",
        "processed JSONL/CSV under `data/interim/`.\n",
        "\n",
        "---\n",
        "\n",
        "### 1) Data Cleaning\n",
        "- Remove empty utterances, stray whitespace, and non-UTF8 chars.  \n",
        "- Normalize speaker names (strip titles, unify casing).  \n",
        "- Handle missing values in `speaker`, `timestamp`.  \n",
        "\n",
        "### 2) Feature Engineering\n",
        "- Add `utterance_len` (token count).  \n",
        "- Add `is_stage_marker` (binary).  \n",
        "- Add `motion_overlap` (rough lexical overlap with motion text).  \n",
        "\n",
        "### 3) Data Transformation\n",
        "- Convert categorical features (e.g. `speaker`) into numeric encodings.  \n",
        "- Ensure output schema matches:  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Save to `data/interim/utterances_prepared.csv`.  \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Paths\n",
        "RAW_DIR = \"data/raw/\"\n",
        "INTERIM_DIR = \"data/interim/\"\n",
        "os.makedirs(INTERIM_DIR, exist_ok=True)\n",
        "\n",
        "# --- 1) LOAD RAW JSONL ---\n",
        "# assume DU phase produced: data/interim/utterances.jsonl\n",
        "utterances_path = os.path.join(INTERIM_DIR, \"utterances.jsonl\")\n",
        "\n",
        "records = []\n",
        "with open(utterances_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            records.append(json.loads(line))\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "print(\"Raw shape:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# --- 2) DATA CLEANING ---\n",
        "\n",
        "# Drop empty utterances\n",
        "df = df[df[\"utterance_text\"].notna() & (df[\"utterance_text\"].str.strip() != \"\")]\n",
        "\n",
        "# Normalize speaker names\n",
        "def normalize_speaker(s):\n",
        "    if pd.isna(s): \n",
        "        return \"UNKNOWN\"\n",
        "    s = re.sub(r\"^Hon\\.?|Dr\\.?|Mr\\.?|Mrs\\.?|Ms\\.?\", \"\", s, flags=re.I)\n",
        "    return s.strip().title()\n",
        "\n",
        "df[\"speaker\"] = df[\"speaker\"].apply(normalize_speaker)\n",
        "\n",
        "# Fill missing timestamps with placeholder\n",
        "df[\"timestamp\"] = df[\"timestamp\"].fillna(\"NA\")\n",
        "\n",
        "print(\"After cleaning:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# --- 3) FEATURE ENGINEERING ---\n",
        "\n",
        "# Length of utterance (tokens)\n",
        "df[\"utterance_len\"] = df[\"utterance_text\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Stage marker flag\n",
        "df[\"is_stage_marker\"] = df[\"stage_marker\"].notna() & (df[\"stage_marker\"].str.strip() != \"\")\n",
        "\n",
        "# Motion text (load from DU artifact)\n",
        "motion_file = [f for f in os.listdir(INTERIM_DIR) if f.endswith(\"_motion.txt\")]\n",
        "motion_text = \"\"\n",
        "if motion_file:\n",
        "    with open(os.path.join(INTERIM_DIR, motion_file[0]), \"r\", encoding=\"utf-8\") as f:\n",
        "        motion_text = f.read()\n",
        "\n",
        "def lexical_overlap(a, b):\n",
        "    if not a or not b:\n",
        "        return 0.0\n",
        "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
        "\n",
        "df[\"motion_overlap\"] = df[\"utterance_text\"].apply(lambda x: lexical_overlap(x, motion_text))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
